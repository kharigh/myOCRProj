{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c1428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from statistics import median\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _word_entry(detection) -> Dict[str, float]:\n",
    "    points, text, confidence = detection\n",
    "    xs = [p[0] for p in points]\n",
    "    ys = [p[1] for p in points]\n",
    "\n",
    "    left = float(min(xs))\n",
    "    right = float(max(xs))\n",
    "    top = float(min(ys))\n",
    "    bottom = float(max(ys))\n",
    "    height = max(1.0, bottom - top)\n",
    "\n",
    "    return {\n",
    "        \"text\": text.strip(),\n",
    "        \"confidence\": float(confidence),\n",
    "        \"left\": left,\n",
    "        \"right\": right,\n",
    "        \"top\": top,\n",
    "        \"bottom\": bottom,\n",
    "        \"height\": height,\n",
    "        \"center_y\": (top + bottom) / 2.0,\n",
    "    }\n",
    "\n",
    "\n",
    "def _load_image_variants(image_path: Path) -> List[np.ndarray]:\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    upscaled = cv2.resize(gray, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    denoised = cv2.fastNlMeansDenoising(upscaled, None, h=18, templateWindowSize=7, searchWindowSize=21)\n",
    "    adaptive = cv2.adaptiveThreshold(\n",
    "        denoised,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        31,\n",
    "        11,\n",
    "    )\n",
    "\n",
    "    otsu = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    return [gray, upscaled, denoised, adaptive, otsu]\n",
    "\n",
    "\n",
    "def _read_detections(reader: easyocr.Reader, image: np.ndarray, numeric_only: bool) -> List:\n",
    "    kwargs = {\n",
    "        \"detail\": 1,\n",
    "        \"paragraph\": False,\n",
    "        \"contrast_ths\": 0.05,\n",
    "        \"adjust_contrast\": 0.7,\n",
    "        \"text_threshold\": 0.45,\n",
    "        \"low_text\": 0.2,\n",
    "        \"width_ths\": 0.5,\n",
    "        \"height_ths\": 0.5,\n",
    "    }\n",
    "    if numeric_only:\n",
    "        kwargs[\"allowlist\"] = \"0123456789-[], \"\n",
    "\n",
    "    return reader.readtext(image, **kwargs)\n",
    "\n",
    "\n",
    "def _best_detections(reader: easyocr.Reader, variants: List[np.ndarray], numeric_only: bool) -> List:\n",
    "    best = []\n",
    "    best_score = -1.0\n",
    "    for variant in variants:\n",
    "        detections = _read_detections(reader, variant, numeric_only=numeric_only)\n",
    "        if not detections:\n",
    "            continue\n",
    "        confidence_sum = sum(float(item[2]) for item in detections)\n",
    "        score = confidence_sum / max(1, len(detections))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = detections\n",
    "    return best\n",
    "\n",
    "\n",
    "def _vertical_overlap_ratio(word: Dict[str, float], line: Dict[str, float]) -> float:\n",
    "    overlap = max(0.0, min(word[\"bottom\"], line[\"bottom\"]) - max(word[\"top\"], line[\"top\"]))\n",
    "    denom = min(word[\"height\"], max(1.0, line[\"median_height\"]))\n",
    "    return overlap / denom\n",
    "\n",
    "\n",
    "def _cluster_lines(words: List[Dict[str, float]]) -> List[List[Dict[str, float]]]:\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    heights = [word[\"height\"] for word in words]\n",
    "    median_height = median(heights)\n",
    "    center_tolerance = max(4.0, 0.35 * median_height)\n",
    "    min_overlap_ratio = 0.45\n",
    "\n",
    "    sorted_words = sorted(words, key=lambda word: (word[\"center_y\"], word[\"left\"]))\n",
    "    line_clusters: List[Dict[str, object]] = []\n",
    "\n",
    "    for word in sorted_words:\n",
    "        best_index = -1\n",
    "        best_score = -1.0\n",
    "\n",
    "        for index, line in enumerate(line_clusters):\n",
    "            overlap_ratio = _vertical_overlap_ratio(word, line)\n",
    "            center_distance = abs(word[\"center_y\"] - line[\"center_y\"])\n",
    "            if overlap_ratio >= min_overlap_ratio or center_distance <= center_tolerance:\n",
    "                score = overlap_ratio - (center_distance / max(center_tolerance, 1.0)) * 0.1\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_index = index\n",
    "\n",
    "        if best_index == -1:\n",
    "            line_clusters.append(\n",
    "                {\n",
    "                    \"items\": [word],\n",
    "                    \"top\": word[\"top\"],\n",
    "                    \"bottom\": word[\"bottom\"],\n",
    "                    \"center_y\": word[\"center_y\"],\n",
    "                    \"median_height\": word[\"height\"],\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        selected = line_clusters[best_index]\n",
    "        selected_items = selected[\"items\"]\n",
    "        selected_items.append(word)\n",
    "        selected[\"top\"] = min(selected[\"top\"], word[\"top\"])\n",
    "        selected[\"bottom\"] = max(selected[\"bottom\"], word[\"bottom\"])\n",
    "        selected[\"center_y\"] = sum(item[\"center_y\"] for item in selected_items) / len(selected_items)\n",
    "        selected[\"median_height\"] = median(item[\"height\"] for item in selected_items)\n",
    "\n",
    "    ordered_lines = sorted(line_clusters, key=lambda line: line[\"center_y\"])\n",
    "    return [sorted(line[\"items\"], key=lambda item: item[\"left\"]) for line in ordered_lines]\n",
    "\n",
    "\n",
    "def _normalize_numeric_text(text: str) -> str:\n",
    "    replacements = str.maketrans(\n",
    "        {\n",
    "            \"O\": \"0\",\n",
    "            \"o\": \"0\",\n",
    "            \"Q\": \"0\",\n",
    "            \"I\": \"1\",\n",
    "            \"l\": \"1\",\n",
    "            \"|\": \"1\",\n",
    "            \"S\": \"5\",\n",
    "            \"s\": \"5\",\n",
    "            \"B\": \"8\",\n",
    "            \"G\": \"6\",\n",
    "            \"g\": \"9\",\n",
    "        }\n",
    "    )\n",
    "    cleaned = text.translate(replacements)\n",
    "    return re.sub(r\"[^0-9,\\-\\s\\[\\]]\", \" \", cleaned)\n",
    "\n",
    "\n",
    "def _number_tokens(detection) -> List[Dict[str, float]]:\n",
    "    points, raw_text, confidence = detection\n",
    "    text = _normalize_numeric_text(raw_text)\n",
    "    numbers = re.findall(r\"-?\\d+\", text)\n",
    "    if not numbers:\n",
    "        return []\n",
    "\n",
    "    xs = [p[0] for p in points]\n",
    "    ys = [p[1] for p in points]\n",
    "    left = float(min(xs))\n",
    "    right = float(max(xs))\n",
    "    top = float(min(ys))\n",
    "    bottom = float(max(ys))\n",
    "    height = max(1.0, bottom - top)\n",
    "    width = max(1.0, right - left)\n",
    "\n",
    "    tokens: List[Dict[str, float]] = []\n",
    "    segment_width = width / max(1, len(numbers))\n",
    "    for idx, token in enumerate(numbers):\n",
    "        token_left = left + idx * segment_width\n",
    "        token_right = token_left + segment_width\n",
    "        tokens.append(\n",
    "            {\n",
    "                \"text\": token,\n",
    "                \"value\": int(token),\n",
    "                \"confidence\": float(confidence),\n",
    "                \"left\": token_left,\n",
    "                \"right\": token_right,\n",
    "                \"top\": top,\n",
    "                \"bottom\": bottom,\n",
    "                \"height\": height,\n",
    "                \"center_y\": (top + bottom) / 2.0,\n",
    "                \"center_x\": (token_left + token_right) / 2.0,\n",
    "            }\n",
    "        )\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def _infer_column_count(rows: List[List[Dict[str, float]]], expected_cols: Optional[int]) -> int:\n",
    "    if expected_cols and expected_cols > 0:\n",
    "        return expected_cols\n",
    "\n",
    "    lengths = [len(row) for row in rows if row]\n",
    "    if not lengths:\n",
    "        return 0\n",
    "\n",
    "    freq: Dict[int, int] = {}\n",
    "    for count in lengths:\n",
    "        freq[count] = freq.get(count, 0) + 1\n",
    "    mode_count = max(freq.items(), key=lambda item: (item[1], -item[0]))[0]\n",
    "    if mode_count <= 1:\n",
    "        return int(median(lengths))\n",
    "    return mode_count\n",
    "\n",
    "\n",
    "def _column_centers(rows: List[List[Dict[str, float]]], columns: int) -> List[float]:\n",
    "    if columns <= 0:\n",
    "        return []\n",
    "\n",
    "    buckets: List[List[float]] = [[] for _ in range(columns)]\n",
    "    for row in rows:\n",
    "        ordered = sorted(row, key=lambda item: item[\"center_x\"])\n",
    "        if len(ordered) < max(2, int(0.8 * columns)):\n",
    "            continue\n",
    "        if len(ordered) == columns:\n",
    "            sampled = ordered\n",
    "        else:\n",
    "            sampled = []\n",
    "            for index in range(columns):\n",
    "                source_index = round(index * (len(ordered) - 1) / max(1, columns - 1))\n",
    "                sampled.append(ordered[source_index])\n",
    "\n",
    "        for idx, token in enumerate(sampled):\n",
    "            buckets[idx].append(token[\"center_x\"])\n",
    "\n",
    "    if any(buckets):\n",
    "        fallback = []\n",
    "        for bucket in buckets:\n",
    "            if bucket:\n",
    "                fallback.append(float(median(bucket)))\n",
    "            elif fallback:\n",
    "                fallback.append(fallback[-1] + 20.0)\n",
    "            else:\n",
    "                fallback.append(0.0)\n",
    "        return fallback\n",
    "\n",
    "    widest_row = max(rows, key=lambda row: len(row), default=[])\n",
    "    widest = sorted(widest_row, key=lambda item: item[\"center_x\"])\n",
    "    if not widest:\n",
    "        return []\n",
    "    if len(widest) == columns:\n",
    "        return [item[\"center_x\"] for item in widest]\n",
    "\n",
    "    min_x = min(item[\"center_x\"] for item in widest)\n",
    "    max_x = max(item[\"center_x\"] for item in widest)\n",
    "    if columns == 1:\n",
    "        return [min_x]\n",
    "    step = (max_x - min_x) / max(1, columns - 1)\n",
    "    return [min_x + idx * step for idx in range(columns)]\n",
    "\n",
    "\n",
    "def _assign_row_to_columns(\n",
    "    row_tokens: List[Dict[str, float]],\n",
    "    centers: List[float],\n",
    ") -> List[Optional[int]]:\n",
    "    rebuilt: List[Optional[int]] = [None] * len(centers)\n",
    "    if not centers:\n",
    "        return rebuilt\n",
    "\n",
    "    for token in sorted(row_tokens, key=lambda item: item[\"center_x\"]):\n",
    "        candidate_order = sorted(\n",
    "            range(len(centers)),\n",
    "            key=lambda index: abs(token[\"center_x\"] - centers[index]),\n",
    "        )\n",
    "        for index in candidate_order:\n",
    "            if rebuilt[index] is None:\n",
    "                rebuilt[index] = token[\"value\"]\n",
    "                break\n",
    "\n",
    "    return rebuilt\n",
    "\n",
    "\n",
    "def _filter_numeric_tokens(tokens: List[Dict[str, float]]) -> List[Dict[str, float]]:\n",
    "    if not tokens:\n",
    "        return []\n",
    "\n",
    "    confident = [token for token in tokens if token[\"confidence\"] >= 0.25]\n",
    "    if not confident:\n",
    "        confident = tokens\n",
    "\n",
    "    lengths = [len(token[\"text\"].lstrip(\"-\")) for token in confident if token[\"text\"].lstrip(\"-\").isdigit()]\n",
    "    if lengths:\n",
    "        freq: Dict[int, int] = {}\n",
    "        for length in lengths:\n",
    "            freq[length] = freq.get(length, 0) + 1\n",
    "        dominant_length = max(freq.items(), key=lambda item: (item[1], item[0]))[0]\n",
    "        confident = [\n",
    "            token\n",
    "            for token in confident\n",
    "            if abs(len(token[\"text\"].lstrip(\"-\")) - dominant_length) <= 1\n",
    "            and len(token[\"text\"].lstrip(\"-\")) >= 2\n",
    "        ]\n",
    "\n",
    "    row_clusters = _cluster_lines(confident)\n",
    "    if not row_clusters:\n",
    "        return confident\n",
    "\n",
    "    row_sizes = [len(row) for row in row_clusters]\n",
    "    typical_row_size = max(2, int(median(row_sizes)))\n",
    "    kept_rows = [row for row in row_clusters if len(row) >= max(2, int(0.5 * typical_row_size))]\n",
    "\n",
    "    filtered: List[Dict[str, float]] = []\n",
    "    for row in kept_rows:\n",
    "        filtered.extend(row)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def extract_lines(image_path: Path) -> List[str]:\n",
    "    if not image_path.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    reader = easyocr.Reader([\"en\"], gpu=False)\n",
    "    variants = _load_image_variants(image_path)\n",
    "    detections = _best_detections(reader, variants, numeric_only=False)\n",
    "\n",
    "    words = [_word_entry(detection) for detection in detections if detection[1].strip()]\n",
    "    grouped_lines = _cluster_lines(words)\n",
    "\n",
    "    line_array: List[str] = []\n",
    "    for line_words in grouped_lines:\n",
    "        line_text = \" \".join(item[\"text\"] for item in line_words if item[\"text\"])\n",
    "        if line_text:\n",
    "            line_array.append(line_text)\n",
    "\n",
    "    return line_array\n",
    "\n",
    "\n",
    "def extract_numeric_array(image_path: Path, expected_cols: Optional[int] = None) -> List[List[Optional[int]]]:\n",
    "    if not image_path.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    reader = easyocr.Reader([\"en\"], gpu=False)\n",
    "    variants = _load_image_variants(image_path)\n",
    "    detections = _best_detections(reader, variants, numeric_only=True)\n",
    "\n",
    "    tokens: List[Dict[str, float]] = []\n",
    "    for detection in detections:\n",
    "        tokens.extend(_number_tokens(detection))\n",
    "\n",
    "    tokens = _filter_numeric_tokens(tokens)\n",
    "\n",
    "    row_clusters = _cluster_lines(tokens)\n",
    "    row_clusters = [sorted(row, key=lambda item: item[\"center_x\"]) for row in row_clusters if row]\n",
    "    if not row_clusters:\n",
    "        return []\n",
    "\n",
    "    columns = _infer_column_count(row_clusters, expected_cols=expected_cols)\n",
    "    centers = _column_centers(row_clusters, columns)\n",
    "\n",
    "    rebuilt = [_assign_row_to_columns(row, centers) for row in row_clusters]\n",
    "    return rebuilt\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser(description=\"OCR line and array extraction\")\n",
    "    parser.add_argument(\"--image\", default=\"pic.jpeg\", help=\"Path to image file\")\n",
    "    parser.add_argument(\"--mode\", choices=[\"lines\", \"array\"], default=\"lines\")\n",
    "    parser.add_argument(\"--cols\", type=int, default=None, help=\"Expected number of array columns\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    image_path = Path(args.image)\n",
    "    if args.mode == \"array\":\n",
    "        array_data = extract_numeric_array(image_path, expected_cols=args.cols)\n",
    "        print(json.dumps(array_data, ensure_ascii=False, indent=2))\n",
    "        return\n",
    "\n",
    "    lines = extract_lines(image_path)\n",
    "    print(json.dumps(lines, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6c1ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image IMAGE] [--mode {lines,array}]\n",
      "                             [--cols COLS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\khari\\AppData\\Roaming\\jupyter\\runtime\\kernel-v379292039e63fcb933b13dc9a41a8a6159b7933ff.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"OCR line and array extraction\")\n",
    "parser.add_argument(\"--image\", default=\"pic.jpeg\", help=\"Path to image file\")\n",
    "parser.add_argument(\"--mode\", choices=[\"lines\", \"array\"], default=\"lines\")\n",
    "parser.add_argument(\"--cols\", type=int, default=None, help=\"Expected number of array columns\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "image_path = Path(args.image)\n",
    "if args.mode == \"array\":\n",
    "    array_data = extract_numeric_array(image_path, expected_cols=args.cols)\n",
    "    print(json.dumps(array_data, ensure_ascii=False, indent=2))\n",
    "\n",
    "lines = extract_lines(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4210d67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"B#Var Vicw 'Csc_ -CPinBikn_Psd_AdcRsult\",\n",
       " 'UI 0Adcvaiodac\" 0 0 (13083 _ 1 8 8 8 0 8 8 G # & \\'7678; 228# #5, % #2,55221%#3,1 10, # 16334 1821_ 16014 16112 16184 16340 , 12892 14858_ 14668 15878, 14668 14669 14668 \"8668418 7a, # \\' E, #3 1393 12873 333 13097 13026 i4866 54666 14666 414 68 ,14669 6 1 6 (16454 5 % 16126 14669 _ 14669 1o?_ 12889 12964 183 _ 13184 13113 14668 14669 14668 13283 14667 14668 E 14668 14565 , 15928 _ 16022 16118, 14665, 14667 14666 14 14665 14667 12995 _ 12948, 14688 , 14666 i4660; 13383 12954 14665 14666 14667 14667 13273 13164 13098 6 15838; 55435 \"16315 55515 , 55888 14663 _ 15983 , 14667 14668 14670 14668 14668 1ozz 13025 1468}_ 1466} 13348 13248 , 13173 13010 . 14663, 14663 , 14664 14663 14664 54877 , 54214, 54664 58658; 5892, 56345 55308; 55537 56362 55537 55537 55538 , 55538 55537 56182 56233 56272 55662 51 5553 _ 551 55531 , 55531 55532 55532 , 55531 , 55512 , 55512 55512 55513 55513 , 1556; 14666; i4665 _ 12926, 14665 13099 13025 , 14665 14665 14666 14667 14664 13199 12814 12887 #83; #8; #866; #4868; 17088 , 1878 1675 14675 14676 14674 16204 14675 14673 16099 16279 16440, 16421 14674 14693, 14663 1683 14692, 14666, 14664, 14664, 14630, 55526, 34880, 54216, 13688;, 13588 14692 14693 14694 12486 , 12499 14694 12830 12738 12649 48587 14663_ 14668 14668, 14669 14669 16481 16569 , 16662 16778 16951, 16815 14665 14667 14667 14666 , 1385 1933 13172 14666 , 14667 13265 13086 13294 12806 12948 14666 ; 14665 #798; #; 14666 , 14666, 14667, 14665 14665 16066 , 16258; 52993 18305; 1398- 15971 16320 , 12925 16153 i663 14665 _ 14626 , 55528 14665 14666 14667 14667 1i8, \\' 1625; 13287 13092 12412 , 55686 , 55514, 53660 , ;16492, i 1667 14666 14666 5888; {5438; 38618; 16153 14667 14667 16343 1693 16527 i _ i66_ 14665 54854 13272 14665 14665 14665 #ooz _ 13187 13107 12922 12960 _ #,88; 55536 = 55536 55536 55536 55536 5553 56183 56338 56339 ; E E 1 \\' 63;, 55583 5553 555.',\n",
       " '8 0 12 S3 G (15424 (15453 {13004 12960 12584 12952 13180 13052 , 16351 , 3 13274 13111 16218 16288 16399 16445 15780 , 12745 16852 16426 , 16120 E 12859 13298; 12849 12896 13173 #588; #8; \"16692 , 16257 16305 16427 160j1, 15261 16352 16129 16197 12426, 16436, 55521, 12942 12867 13168 13035 12988 13094 16315 16353 16361 55943_ 16034 16143 16204 16268 _ E 12995 55466; 13155 13088 13045 13001 62, 55 15415 15468 , 15488 _ 55288; 15379 , 15447 15332 , ##; 55516 55437 55515 55515 55515 55516_ 55514 #c; #798; 55550, 15630 , 12861 55551, 54442 , 15724 , 12957 55551, 15474 55550, 15611 55551 55551 , 55551 , 15592 15633 15539 _ 15567 #2; 1963, 13195 12915 12876 13081 13011 12957 165 38 , 16634 16336, 12995 16723 , 16790, 16829, 16878, 16875 , 12683; 12723 12570 12532, 12369 , 12491 , 12816 12637 1593_ 588 6; #% 16196 16244 16292 16336, 16113 16461 , 15990 , 12949, 15582 , E #58 13015 12955 , 13195 12974 15028 16001 16109 16198 io1, 16252 16290 16355 88; %98; G 1155 13049 12966 , 12908 12875 12795 15376 15422 15516 15541 (15463 15491 , 15574 54865, H52_ 55526 55526 55525 55526 55525 55523 , 55525 55525 0 3 55 55']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.7.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
